source('text_processing_functions.R')
source('vis_calculation_functions.R')
test = tokenize('nyt-collection-text/art/0068412.txt')
unique_test = filter_unique(test)
unique_test = filter_stopwords(unique_test, 'stopwords_xpo6.csv')
weights = weight_by_counts(unique_test, test)
weights = filter_rare(weights, nmin=5)
bounding_boxes = bounding_box(names(weights))
weights = sort_by_weight(weights)
coordinates = place_words(weights, bounding_boxes)
